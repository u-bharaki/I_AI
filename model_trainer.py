import pandas as pd
import numpy as np
import cv2  # OpenCV (gÃ¶rÃ¼ntÃ¼ iÅŸleme iÃ§in)
import os
from tqdm import tqdm  # GÃ¼zel bir ilerleme Ã§ubuÄŸu iÃ§in
import warnings

# Model kÃ¼tÃ¼phaneleri
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# UyarÄ±larÄ± gizle (Logistic Regression'daki max_iter uyarÄ±larÄ± iÃ§in)
warnings.filterwarnings('ignore')

# --- 1. AYARLAR ---
# BU KISIMLARI KENDÄ° PROJENÄ°ZE GÃ–RE DÃœZENLEYÄ°N
IMG_SIZE = 32  # 32x32 piksel (Daha hÄ±zlÄ± eÄŸitim iÃ§in dÃ¼ÅŸÃ¼k tutuldu)
DATA_DIR = "preprocessed_images"  # GÃ¶rÃ¼ntÃ¼lerin olduÄŸu ana klasÃ¶r
CSV_PATH = "cleaned_file_final.csv"  # GÃ¶rÃ¼ntÃ¼deki CSV dosyanÄ±zÄ±n yolu
RANDOM_STATE = 42  # SonuÃ§larÄ±n tekrarlanabilir olmasÄ± iÃ§in


# --- --- --- --- --- --- --- --- --- --- --- ---

def load_and_prepare_data(csv_path, data_dir, img_size):
    """
    CSV dosyasÄ±nÄ± okur, gÃ¶rÃ¼ntÃ¼leri yÃ¼kler, demografik verilerle birleÅŸtirir
    ve modellerin anlayacaÄŸÄ± X, y formatÄ±na getirir.
    """
    try:
        df = pd.read_csv(csv_path)
    except FileNotFoundError:
        print(f"HATA: {csv_path} dosyasÄ± bulunamadÄ±. LÃ¼tfen CSV_PATH deÄŸiÅŸkenini kontrol edin.")
        return None, None, None

    # Eksik verileri temizle
    df.dropna(subset=['filepath', 'Diagnosis', 'Patient Age', 'Patient Sex'], inplace=True)
    df['Patient Age'] = pd.to_numeric(df['Patient Age'], errors='coerce')
    df.dropna(subset=['Patient Age'], inplace=True)  # SayÄ±ya dÃ¶nÃ¼ÅŸmeyenleri at

    print(f"Toplam {len(df)} geÃ§erli satÄ±r bulundu. Ã–zellikler Ã§Ä±karÄ±lÄ±yor...")

    X_features = []  # 3074 (2 + 3072) boyutlu vektÃ¶rler buraya
    y_labels = []  # Etiketler buraya

    # tqdm ile ilerleme Ã§ubuÄŸu oluÅŸtur
    for index, row in tqdm(df.iterrows(), total=len(df), desc="GÃ¶rÃ¼ntÃ¼ler iÅŸleniyor"):
        try:
            # 1. GÃ¶rÃ¼ntÃ¼ Ã–zellikleri (3072 Ã¶zellik)
            img_path = os.path.join(data_dir, row['filepath'])
            if not os.path.exists(img_path):
                # print(f"UyarÄ±: {img_path} bulunamadÄ±, atlanÄ±yor.")
                continue

            image = cv2.imread(img_path)
            img_resized = cv2.resize(image, (img_size, img_size))
            img_flat = img_resized.flatten()
            img_norm = img_flat / 255.0

            # 2. Demografik Ã–zellikler (2 Ã¶zellik)
            age = row['Patient Age']
            sex = 1 if row['Patient Sex'] == 'Male' else 0

            # 3. TÃ¼m Ã–zellikleri BirleÅŸtir (3074 Ã¶zellik)
            final_feature_vector = np.concatenate(([age, sex], img_norm))

            X_features.append(final_feature_vector)
            y_labels.append(row['Diagnosis'])

        except Exception as e:
            # print(f"Hata: {img_path} iÅŸlenemedi. Hata: {e}, atlanÄ±yor.")
            pass  # Bozuk dosyalarÄ± veya yollarÄ± atla

    if not X_features:
        print("HATA: HiÃ§bir gÃ¶rÃ¼ntÃ¼ iÅŸlenemedi. DATA_DIR yolunu ve dosya adlarÄ±nÄ± kontrol edin.")
        return None, None, None

    # Listeleri NumPy dizisine Ã§evir
    X = np.array(X_features)

    # Etiketleri metinden sayÄ±ya Ã§evir (Label Encoding)
    le = LabelEncoder()
    y = le.fit_transform(y_labels)

    print(f"\nÃ–zellik Ã§Ä±karma tamamlandÄ±: X ÅŸekli {X.shape}, y ÅŸekli {y.shape}")
    return X, y, le


def main():
    # --- 2. VERÄ° HAZIRLAMA ---
    X, y, label_encoder = load_and_prepare_data(CSV_PATH, DATA_DIR, IMG_SIZE)

    # Veri yÃ¼klenemediyse programÄ± durdur
    if X is None:
        return

    # --- 3. TRAIN/TEST SPLIT VE Ã–LÃ‡EKLEME (SCALING) ---
    print("\nVeri Train/Test olarak ayrÄ±lÄ±yor ve Ã¶lÃ§ekleniyor...")

    # Veriyi Train ve Test olarak ayÄ±r
    # stratify=y, sÄ±nÄ±flarÄ±n (Diagnosis) train ve test setine orantÄ±lÄ± daÄŸÄ±lmasÄ±nÄ± saÄŸlar
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.25,  # Verinin %25'ini test iÃ§in ayÄ±r
        random_state=RANDOM_STATE,
        stratify=y
    )

    # Veriyi Ã–lÃ§ekle (StandardScaler)
    # Bu adÄ±m KNN ve Logistic Regression iÃ§in KRÄ°TÄ°KTÄ°R.
    # YaÅŸ (0-90) ve Pikseller (0-1) farklÄ± Ã¶lÃ§eklerde olduÄŸu iÃ§in aynÄ± Ã¶lÃ§eÄŸe getirir.
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    print("Veri eÄŸitime hazÄ±r.")

    # --- 4. MODELLERÄ°N TANIMLANMASI ---

    # EÄŸitilecek tÃ¼m modelleri bir sÃ¶zlÃ¼k (dictionary) iÃ§inde tanÄ±mla
    models = {
        "Logistic Regression": LogisticRegression(
            random_state=RANDOM_STATE,
            solver='saga',  # BÃ¼yÃ¼k veri setleri iÃ§in daha hÄ±zlÄ± bir Ã§Ã¶zÃ¼cÃ¼
            max_iter=1000,  # Modelin yakÄ±nsamasÄ± iÃ§in yeterli iterasyon
            n_jobs=-1  # TÃ¼m CPU Ã§ekirdeklerini kullan
        ),
        "K-Nearest Neighbors (KNN)": KNeighborsClassifier(
            n_neighbors=7,  # KomÅŸu sayÄ±sÄ± (deneyerek ayarlanabilir)
            n_jobs=-1
        ),
        "Decision Tree": DecisionTreeClassifier(
            random_state=RANDOM_STATE,
            max_depth=10  # AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) engellemek iÃ§in derinliÄŸi sÄ±nÄ±rla
        ),
        "Random Forest": RandomForestClassifier(
            random_state=RANDOM_STATE,
            n_estimators=100,  # 100 adet karar aÄŸacÄ± kullan
            max_depth=10,
            n_jobs=-1
        )
    }

    # SonuÃ§larÄ± saklamak iÃ§in bir sÃ¶zlÃ¼k
    results = {}

    # --- 5. MODEL EÄÄ°TÄ°MÄ° VE DEÄERLENDÄ°RME DÃ–NGÃœSÃœ ---
    print("\n" + "=" * 30)
    print(" MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR ")
    print("=" * 30)

    for name, model in models.items():
        print(f"\n[{name}] modeli eÄŸitiliyor...")

        # Modeli Ã¶lÃ§eklenmiÅŸ veri ile eÄŸit
        model.fit(X_train_scaled, y_train)

        # Test verisi ile tahmin yap
        y_pred = model.predict(X_test_scaled)

        # BaÅŸarÄ± oranÄ±nÄ± (accuracy) hesapla
        score = accuracy_score(y_test, y_pred)

        # Sonucu kaydet
        results[name] = score

        print(f"[{name}] Test BaÅŸarÄ± OranÄ±: {score * 100:.2f}%")

    # --- 6. SONUÃ‡LARIN KARÅILAÅTIRILMASI ---
    print("\n" + "=" * 40)
    print(" TÃœM MODELLERÄ°N KARÅILAÅTIRMASI ")
    print("=" * 40)

    # SonuÃ§larÄ± bir DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rerek daha gÃ¼zel gÃ¶ster
    results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Test Accuracy'])
    results_df['Test Accuracy'] = (results_df['Test Accuracy'] * 100).round(2)  # YÃ¼zdeye Ã§evir

    # En baÅŸarÄ±lÄ±dan en baÅŸarÄ±sÄ±z olana doÄŸru sÄ±rala
    results_df = results_df.sort_values(by='Test Accuracy', ascending=False)

    print(results_df)

    print("\n" + "-" * 40)
    best_model_name = results_df.index[0]
    best_model_score = results_df.iloc[0, 0]
    print(f"ğŸ† En baÅŸarÄ±lÄ± model: {best_model_name} (BaÅŸarÄ±: {best_model_score}%)")
    print("-" * 40)


if __name__ == "__main__":
    main()